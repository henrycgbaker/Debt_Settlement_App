{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9620bbb0e074ae180ce2cd2811ae957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3675122d78dd403cb6efd4113197968b",
              "IPY_MODEL_fe023ace34544f818aec3be7b9608c35",
              "IPY_MODEL_43931593356a49468dc3089fe62ab57e"
            ],
            "layout": "IPY_MODEL_effdee6ebc9d4220a398e3c7a8d32002"
          }
        },
        "3675122d78dd403cb6efd4113197968b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03ee9e0822ba433492e084d3a69815bd",
            "placeholder": "​",
            "style": "IPY_MODEL_17857dcb4fd642c4a2ef21fc0246f681",
            "value": "model.safetensors: 100%"
          }
        },
        "fe023ace34544f818aec3be7b9608c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3c000601cf45e1a047fe89f05204f2",
            "max": 10241912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61fcf939c7ad4138b8eae631a4c8beaf",
            "value": 10241912
          }
        },
        "43931593356a49468dc3089fe62ab57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4060b8012a83480b91bbf4a02c6c604c",
            "placeholder": "​",
            "style": "IPY_MODEL_8b3d08bec17a4afea6ca105c5b5361aa",
            "value": " 10.2M/10.2M [00:00&lt;00:00, 34.4MB/s]"
          }
        },
        "effdee6ebc9d4220a398e3c7a8d32002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ee9e0822ba433492e084d3a69815bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17857dcb4fd642c4a2ef21fc0246f681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb3c000601cf45e1a047fe89f05204f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fcf939c7ad4138b8eae631a4c8beaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4060b8012a83480b91bbf4a02c6c604c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3d08bec17a4afea6ca105c5b5361aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henrycgbaker/Debt_Settlement_App/blob/main/uncertainty_celeba_TTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1Hya6gUtChbP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3jCFv37PI-Z",
        "outputId": "d052bfbb-5d4f-4837-e72b-5ec7785f5da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Ny3af7iB1n3y0QYf9vpBN_x76Ti2MRtW\n",
            "From (redirected): https://drive.google.com/uc?id=1Ny3af7iB1n3y0QYf9vpBN_x76Ti2MRtW&confirm=t&uuid=e1413add-ce7a-443f-ae1c-fa134025b593\n",
            "To: /content/celeba_300.zip\n",
            "100% 66.3M/66.3M [00:01<00:00, 42.1MB/s]\n",
            "Archive:  celeba_300.zip\n",
            "replace celeba_300/dataset_info.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# Download and extract dataset\n",
        "!gdown 1Ny3af7iB1n3y0QYf9vpBN_x76Ti2MRtW # NB this is not the same as the one Carol has in latest uncertainty_celeba.ipynb\n",
        "!unzip celeba_300.zip\n",
        "!rm celeba_300.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "ORfvdzZ_Uogs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebA300Dataset(Dataset):\n",
        "    def __init__(self, root_dir='celeba_300'):\n",
        "        # Load metadata\n",
        "        info = torch.load(os.path.join(root_dir, 'dataset_info.pt'))\n",
        "        self.metadata = info['metadata']\n",
        "        self.n_classes = info['n_classes']\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "        # Define transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_data = self.metadata[idx]\n",
        "        img_path = os.path.join(self.root_dir, 'images/img_align_celeba', img_data['img_name'])\n",
        "\n",
        "        # Load and transform image\n",
        "        image = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_data['identity']\n",
        "\n",
        "# Create dataset and splits\n",
        "def create_data_loaders(batch_size=32, train_split=0.8):\n",
        "    dataset = CelebA300Dataset()\n",
        "\n",
        "    # Calculate splits\n",
        "    train_size = int(train_split * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "\n",
        "    # Create splits\n",
        "    train_dataset, test_dataset = random_split(\n",
        "        dataset,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    # Create loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    print(f\"Training samples: {len(train_dataset)}\")\n",
        "    print(f\"Testing samples: {len(test_dataset)}\")\n",
        "\n",
        "    return train_loader, test_loader, dataset.n_classes"
      ],
      "metadata": {
        "id": "ZZuYic_ERC8U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "CbBYXixnUjfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up model, training and uncertainty\n",
        "\n",
        "class FaceClassifier(nn.Module):\n",
        "    def __init__(self, num_classes, dropout_rate=0):\n",
        "        super().__init__()\n",
        "        # Load model from timm\n",
        "        self.model = timm.create_model(\n",
        "            'mobilenetv3_small_100',\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes,\n",
        "            drop_rate=dropout_rate\n",
        "        )\n",
        "\n",
        "        # Add extra dropout for uncertainty\n",
        "        self.model.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            self.model.classifier\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def enable_dropout(self):\n",
        "        for m in self.model.modules():\n",
        "            if isinstance(m, nn.Dropout):\n",
        "                m.train()\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc='Training'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    return running_loss / len(train_loader), accuracy\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc='Evaluating'):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    return running_loss / len(test_loader), accuracy"
      ],
      "metadata": {
        "id": "GxarmcmHROly"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_loader, test_loader, num_classes = create_data_loaders(batch_size=32)\n",
        "\n",
        "model = FaceClassifier(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    # Adjust learning rate\n",
        "    scheduler.step(test_acc)\n",
        "\n",
        "    # Save best model\n",
        "    if test_acc > best_accuracy:\n",
        "        best_accuracy = test_acc\n",
        "        torch.save(model.state_dict(), 'best_face_model.pt')\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
        "    print('-' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9620bbb0e074ae180ce2cd2811ae957",
            "3675122d78dd403cb6efd4113197968b",
            "fe023ace34544f818aec3be7b9608c35",
            "43931593356a49468dc3089fe62ab57e",
            "effdee6ebc9d4220a398e3c7a8d32002",
            "03ee9e0822ba433492e084d3a69815bd",
            "17857dcb4fd642c4a2ef21fc0246f681",
            "fb3c000601cf45e1a047fe89f05204f2",
            "61fcf939c7ad4138b8eae631a4c8beaf",
            "4060b8012a83480b91bbf4a02c6c604c",
            "8b3d08bec17a4afea6ca105c5b5361aa"
          ]
        },
        "id": "qgR4KmdERSEr",
        "outputId": "87f03461-b152-49d1-cbe1-992b11786d7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-43d61689973a>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  info = torch.load(os.path.join(root_dir, 'dataset_info.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 7230\n",
            "Testing samples: 1808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/10.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9620bbb0e074ae180ce2cd2811ae957"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:23<00:00,  9.77it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:05<00:00, 10.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10:\n",
            "Train Loss: 5.4093, Train Acc: 1.94%\n",
            "Test Loss: 5.3534, Test Acc: 3.32%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:20<00:00, 10.79it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:05<00:00, 10.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10:\n",
            "Train Loss: 4.2633, Train Acc: 9.43%\n",
            "Test Loss: 5.1993, Test Acc: 4.04%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:23<00:00,  9.66it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10:\n",
            "Train Loss: 3.4299, Train Acc: 20.26%\n",
            "Test Loss: 3.8522, Test Acc: 16.92%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:23<00:00,  9.68it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 11.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10:\n",
            "Train Loss: 2.7590, Train Acc: 31.80%\n",
            "Test Loss: 3.2157, Test Acc: 26.00%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:22<00:00, 10.12it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10:\n",
            "Train Loss: 2.2429, Train Acc: 42.64%\n",
            "Test Loss: 3.5308, Test Acc: 24.45%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:22<00:00, 10.19it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10:\n",
            "Train Loss: 1.8221, Train Acc: 50.93%\n",
            "Test Loss: 3.3793, Test Acc: 27.38%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:22<00:00,  9.98it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:05<00:00, 11.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10:\n",
            "Train Loss: 1.4246, Train Acc: 60.90%\n",
            "Test Loss: 3.0542, Test Acc: 34.46%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:22<00:00,  9.92it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10:\n",
            "Train Loss: 1.1066, Train Acc: 68.52%\n",
            "Test Loss: 3.0978, Test Acc: 35.90%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:22<00:00, 10.21it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 11.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10:\n",
            "Train Loss: 0.8665, Train Acc: 74.81%\n",
            "Test Loss: 2.8987, Test Acc: 41.04%\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 226/226 [00:24<00:00,  9.29it/s]\n",
            "Evaluating: 100%|██████████| 57/57 [00:04<00:00, 11.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10:\n",
            "Train Loss: 0.6641, Train Acc: 80.35%\n",
            "Test Loss: 2.9435, Test Acc: 45.13%\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test-Time Augmentation (TTA)\n",
        "\n",
        "Here’s how to implement Test-Time Augmentation (TTA) for uncertainty estimation using a pre-trained model. TTA involves applying augmentations to the input image during inference and analyzing the variability in predictions.\n",
        "\n",
        "Here, uncertainty is the standard deviation of predictions across augmented images (TTA).\n",
        "\n",
        "Steps:\n",
        "\n",
        "* Generate predictions for each augmentation.\n",
        "* Aggregate predictions into a probability distribution for each class.\n",
        "* Calculate the standard deviation across the predictions for the augmented images."
      ],
      "metadata": {
        "id": "POTc73RkcPQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ttach as tta\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define image transformations (match your dataset's preprocessing)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load a single image\n",
        "image_path = \"celeba_300/images/img_align_celeba/157647.jpg\"  # Replace with your image path\n",
        "image = Image.open(image_path)\n",
        "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Move image to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_tensor = input_tensor.to(device)\n",
        "\n",
        "# Wrap the model with TTA\n",
        "tta_transforms = tta.Compose([\n",
        "    tta.HorizontalFlip(),\n",
        "    tta.Rotate90(angles=[0, 90, 180, 270]),\n",
        "])\n",
        "\n",
        "# Store predictions for all augmentations\n",
        "model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for transform in tta_transforms:\n",
        "        # Apply each augmentation\n",
        "        augmented_tensor = transform.augment_image(input_tensor)\n",
        "        outputs = model(augmented_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        all_predictions.append(probabilities.cpu().numpy())\n",
        "\n",
        "# Convert list to a numpy array for easy calculations\n",
        "all_predictions = np.array(all_predictions)  # Shape: [num_augmentations, batch_size, num_classes]\n",
        "\n",
        "# Calculate mean prediction across augmentations\n",
        "mean_prediction = np.mean(all_predictions, axis=0)  # Shape: [batch_size, num_classes]\n",
        "\n",
        "# Calculate uncertainty as standard deviation across augmentations\n",
        "uncertainty = np.std(all_predictions, axis=0)  # Shape: [batch_size, num_classes]\n",
        "\n",
        "# Display results\n",
        "predicted_class = np.argmax(mean_prediction, axis=1).item()\n",
        "uncertainty_score = uncertainty[0, predicted_class]\n",
        "\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "print(f\"Uncertainty score (std-dev for class {predicted_class}): {uncertainty_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YMjYSVSeD3R",
        "outputId": "db53db48-609a-4221-99c5-ae3b8ab58408"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 31\n",
            "Uncertainty score (std-dev for class 31): 0.3481\n"
          ]
        }
      ]
    }
  ]
}